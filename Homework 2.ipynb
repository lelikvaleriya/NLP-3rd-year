{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_rus = 'Ты белых лебедей кормила, откинув тяжесть черных кос… Я рядом плыл; сошлись кормила; Закатный луч был странно кос. По небу полосы синели, вечеровой багрец кроя; В цветах черемух и синели скрывались водные края. Все формы были строго чётки, миг ранил сердце сотней жал… Я, как аскет сжимает чётки, в руке весло невольно жал. Вдруг лебедей метнулась пара… Не знаю, чья была вина… Закат замлел за дымкой пара, алея, как поток вина. Была то правда ли, мечта ли, уста двоих слились в одно. Две лодки, как и мы, мечтали, и будто вонзены во дно. Я свуто помню эту встречу: пруд, берег, неба яркий плат… Миг тот же если вновь я встречу, и жизнь ничтожная из плат!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст сложен для разбора парсерами, так как каждая 2 и 4 строчка четверостишья заканчиваются омонимами. Слово вечеровой возможно также будет представлять сложность, так как оно является либо авторским, либо устаревшим. В последнем четверостишии слово свято заменено на свуто, чтобы проверить, насколько парсеры будут чувствительны к опечаткам, если суффикс части речи сохранен. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ты белых лебедей кормила, откинув тяжесть черных кос… Я рядом плыл; сошлись кормила; Закатный луч был странно кос. По небу полосы синели, вечеровой багрец кроя; В цветах черемух и синели скрывались водные края. Все формы были строго чётки, миг ранил сердце сотней жал… Я, как аскет сжимает чётки, в руке весло невольно жал. Вдруг лебедей метнулась пара… Не знаю, чья была вина… Закат замлел за дымкой пара, алея, как поток вина. Была то правда ли, мечта ли, уста двоих слились в одно. Две лодки, как и мы, мечтали, и будто вонзены во дно. Я свуто помню эту встречу: пруд, берег, неба яркий плат… Миг тот же если вновь я встречу, и жизнь ничтожная из плат!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_rus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем вектор с вручную размеченными частями речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_rus_test = ['PRON', 'ADJ', 'NOUN', 'V', 'V', 'NOUN', 'ADJ', 'NOUN', 'PRON', 'A', 'V', 'V', 'NOUN', 'ADJ', 'NOUN', 'V', 'A', 'ADJ', 'PREP', 'NOUN', 'NOUN', 'V', 'ADJ', 'NOUN', 'V', 'PREP', 'NOUN', 'NOUN', 'CONJ', 'NOUN', 'V', 'ADJ', 'NOUN', 'PRON', 'NOUN', 'V', 'A', 'ADJ', 'NOUN', 'V', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'CONJ', 'NOUN', 'V', 'NOUN', 'PREP', 'NOUN', 'NOUN', 'A', 'V', 'A', 'NOUN', 'V', 'NOUN', 'PART', 'V', 'PRON', 'V', 'NOUN', 'NOUN', 'V', 'PREP', 'NOUN', 'NOUN', 'V', 'CONJ', 'NOUN', 'NOUN', 'V', 'PRON', 'NOUN', 'CONJ', 'NOUN', 'CONJ', 'NOUN', 'NUM', 'V', 'PREP', 'NUM', 'NUM', 'NOUN', 'CONJ', 'CONJ', 'PRON', 'V', 'CONJ', 'CONJ', 'V', 'PREP', 'NOUN', 'PRON', 'A', 'V', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'PRON', 'PART', 'CONJ', 'A', 'PRON', 'V', 'CONJ', 'NOUN', 'ADJ', 'PREP', 'NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(morph_rus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_eng = '''''The summer dance. The count invited his neighbors to a summer ball. To prepare for the event, he hired a farmer to clean the castle yard. There was wood to chop with a saw, and there was a nag that needed to be fed. While the chores were being completed, the count walked down the path to the garden. The date listed on his watch showed May. He shed a tear as he stared at the plot of dirt that now looked like a desert. He remembered the date as if it were yesterday. Even now, when the count thought about his prized roses, it was more than he could bear.'''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph_eng_test = ['DT', 'NOUN', 'NOUN', 'DT', 'NOUN', 'V', 'PRON', 'NOUN', 'PREP', 'DT', 'NOUN', 'NOUN', 'PREP', 'V', 'PREP', 'DT', 'NOUN', 'PRON', 'V', 'DT', 'NOUN', 'PREP', 'V', 'DT', 'NOUN', 'NOUN', 'A', 'V', 'NOUN', 'PREP', 'V', 'PREP', 'DT', 'NOUN', 'CC', 'A', 'V', 'DT', 'NOUN', 'NOUN', 'V', 'PREP', 'V', 'V', 'CC', 'DT', 'NOUN', 'V', 'V', 'V', 'DT', 'NOUN', 'V', 'PREP', 'DT', 'NOUN', 'PREP', 'DT', 'NOUN', 'DT', 'NOUN', 'V', 'PREP', 'PRON', 'NOUN', 'V', 'NOUN', 'PRON', 'V', 'DT', 'NOUN', 'CC', 'PRON', 'V', 'PREP', 'DT', 'NOUN', 'PREP', 'NOUN', 'NOUN', 'A', 'V', 'A', 'DT', 'NOUN', 'PRON', 'V', 'DT', 'NOUN', 'CC', 'CC', 'PRON', 'V', 'A', 'CC', 'A', 'CC', 'DT', 'NOUN', 'V', 'PREP', 'NOUN', 'V', 'NOUN', 'PRON', 'V', 'A', 'CC', 'PRON', 'V', 'V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(morph_eng_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"''The summer dance. The count invited his neighbors to a summer ball. To prepare for the event, he hired a farmer to clean the castle yard. There was wood to chop with a saw, and there was a nag that needed to be fed. While the chores were being completed, the count walked down the path to the garden. The date listed on his watch showed May. He shed a tear as he stared at the plot of dirt that now looked like a desert. He remembered the date as if it were yesterday. Even now, when the count thought about his prized roses, it was more than he could bear.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом тексте также есть несколько омонимов, при работе с которыми у парсеров возможно будут возникать проблемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Автоматическая разметка русского текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_txt(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r'[^\\w\\s]','', txt)\n",
    "    return(txt) #функция приводит к нижнему регистру и чистит от знаков препинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = clean_txt(txt_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pym = []\n",
    "for token in rus.split():\n",
    "    tok = m.parse(token)\n",
    "    first = tok[0]\n",
    "    tag = first.tag\n",
    "    tag2 = str(tag)\n",
    "    tag3 = tag2.split(',')\n",
    "    tag4 = tag3[0].split(' ')\n",
    "    train_pym.append(tag4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NPRO',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'GRND',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NPRO',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'VERB',\n",
       " 'VERB',\n",
       " 'ADJF',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'ADVB',\n",
       " 'NOUN',\n",
       " 'PREP',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'PREP',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'CONJ',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'ADJF',\n",
       " 'NOUN',\n",
       " 'ADJF',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'ADVB',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NPRO',\n",
       " 'CONJ',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'PREP',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'ADVB',\n",
       " 'NOUN',\n",
       " 'ADVB',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'PRCL',\n",
       " 'VERB',\n",
       " 'ADJF',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'PREP',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'GRND',\n",
       " 'CONJ',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'CONJ',\n",
       " 'PRCL',\n",
       " 'PRCL',\n",
       " 'NOUN',\n",
       " 'PRCL',\n",
       " 'NOUN',\n",
       " 'NUMR',\n",
       " 'VERB',\n",
       " 'PREP',\n",
       " 'ADJF',\n",
       " 'NUMR',\n",
       " 'NOUN',\n",
       " 'CONJ',\n",
       " 'CONJ',\n",
       " 'NPRO',\n",
       " 'VERB',\n",
       " 'CONJ',\n",
       " 'CONJ',\n",
       " 'PRTS',\n",
       " 'PREP',\n",
       " 'NOUN',\n",
       " 'NPRO',\n",
       " 'PRTS',\n",
       " 'VERB',\n",
       " 'ADJF',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'ADJF',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'ADJF',\n",
       " 'PRCL',\n",
       " 'CONJ',\n",
       " 'ADVB',\n",
       " 'NPRO',\n",
       " 'NOUN',\n",
       " 'CONJ',\n",
       " 'NOUN',\n",
       " 'ADJF',\n",
       " 'PREP',\n",
       " 'NOUN']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pym #результат для пайморфи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = my.analyze(rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SPRO', 'A', 'S', 'V', 'V', 'S', 'A', 'S', 'SPRO', 'ADV', 'V', 'V', 'V', 'A', 'S', 'V', 'ADV', 'S', 'PR', 'S', 'S', 'V', 'S', 'S', 'S', 'PR', 'S', 'S', 'CONJ', 'V', 'V', 'A', 'S', 'APRO', 'S', 'V', 'ADV', 'A', 'S', 'V', 'S', 'S', 'V', 'SPRO', 'CONJ', 'S', 'V', 'S', 'PR', 'S', 'S', 'ADV', 'V', 'ADV', 'S', 'V', 'S', 'PART', 'V', 'APRO', 'V', 'S', 'S', 'V', 'PR', 'S', 'S', 'S', 'CONJ', 'S', 'S', 'V', 'CONJ', 'ADV', 'PART', 'S', 'PART', 'S', 'NUM', 'V', 'PR', 'ANUM', 'NUM', 'S', 'CONJ', 'CONJ', 'SPRO', 'V', 'CONJ', 'PART', 'V', 'PR', 'S', 'SPRO', 'A', 'V', 'APRO', 'S', 'S', 'S', 'S', 'A', 'S', 'S', 'APRO', 'PART', 'CONJ', 'ADV', 'SPRO', 'S', 'CONJ', 'S', 'A', 'PR', 'S']\n"
     ]
    }
   ],
   "source": [
    "train_mystem = []\n",
    "for word in ana:\n",
    "    if 'analysis' in word:\n",
    "        gr = word['analysis'][0]['gr']\n",
    "        pos = gr.split('=')[0].split(',')[0]\n",
    "        train_mystem.append(pos)\n",
    "print(train_mystem) #результат для майстема"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Doc(rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_splitted = rus.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "doc.parse_syntax(syntax_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = doc.sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sent.morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "natasha_pos = []\n",
    "for el in t:\n",
    "    natasha_pos.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_list = list(natasha_pos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRON', 'ADJ', 'NOUN', 'VERB', 'ADJ', 'NOUN', 'ADJ', 'NOUN', 'PRON', 'ADV', 'VERB', 'ADV', 'VERB', 'ADJ', 'NOUN', 'AUX', 'ADV', 'ADJ', 'ADP', 'NOUN', 'NOUN', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'CCONJ', 'NOUN', 'VERB', 'ADJ', 'NOUN', 'DET', 'NOUN', 'AUX', 'ADV', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'NOUN', 'NOUN', 'PRON', 'SCONJ', 'NOUN', 'VERB', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'ADV', 'VERB', 'ADV', 'NOUN', 'VERB', 'NOUN', 'PART', 'VERB', 'DET', 'AUX', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'VERB', 'SCONJ', 'NOUN', 'NOUN', 'AUX', 'DET', 'NOUN', 'PART', 'NOUN', 'PART', 'NOUN', 'NUM', 'VERB', 'ADP', 'NUM', 'NUM', 'NOUN', 'SCONJ', 'PART', 'PRON', 'VERB', 'CCONJ', 'PART', 'VERB', 'ADP', 'NOUN', 'PRON', 'VERB', 'VERB', 'DET', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'DET', 'PART', 'SCONJ', 'ADV', 'PRON', 'NOUN', 'PART', 'NOUN', 'ADJ', 'ADP', 'NOUN']\n"
     ]
    }
   ],
   "source": [
    "train_natasha = []\n",
    "for el in norm_list:\n",
    "    el = list(el)\n",
    "    train_natasha.append(el[1])\n",
    "print(train_natasha) #результат для наташи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_natasha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertizer(pos_list):\n",
    "    #new_list = []\n",
    "    for el in pos_list:\n",
    "        if el == 'NOUN' or el == 'S' or el == 'NN':\n",
    "            el = el.replace(el, 'NOUN')\n",
    "            #pos_list.append(el)\n",
    "    return(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertizer(pos_list):\n",
    "    new_list = []\n",
    "    for el in pos_list:\n",
    "        if el == 'NN':\n",
    "            new_el = el.replace('NN', 'NOUN')\n",
    "            new_list.append(new_el)\n",
    "        if el == 'S':\n",
    "            new_el = el.replace('S', 'NOUN')\n",
    "            new_list.append(new_el)\n",
    "        if el == 'VERB':\n",
    "            new_el = el.replace('VERB', 'V')\n",
    "            new_list.append(new_el)\n",
    "        if el == 'GRND':\n",
    "            new_el = el.replace('GRND', 'V')\n",
    "            new_list.append(new_el)\n",
    "        else:\n",
    "            new_list.append(el)\n",
    "    return(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertizer(pos_list):\n",
    "    new_list = []\n",
    "    for el in pos_list:\n",
    "        if el == 'NOUN' or el == 'S' or el == 'NN' or el == 'NNS':\n",
    "            new_list.append('NOUN')\n",
    "        if el == 'V' or el == 'VERB' or el == 'GRND' or el == 'VB' or el == 'VBG' or el == 'VBD' or el == 'VBZ' or el == 'VBN' or el == 'PRTS' or el == 'VBN' or el == 'MD' or el == 'AUX':\n",
    "            new_list.append('V')\n",
    "        if el == 'ADJ' or el == 'ADJF' or el == 'A' or el == 'JJ':\n",
    "            new_list.append('ADJ')\n",
    "        if el == 'ADV' or el == 'ADVB' or el == 'RB' or el == 'WRB' or el == 'EX':\n",
    "            new_list.append('A')\n",
    "        if 'PRO' in el or el == 'WDT':\n",
    "            new_list.append('PRON')\n",
    "        if el == 'PREP' or el == 'PR' or el == 'ADP' or el =='PRP$' or el == 'PRP' or el == 'TO' or el == 'IN':\n",
    "            new_list.append('PREP')\n",
    "        if el == 'DT' or el == 'DET':\n",
    "            new_list.append('DT')\n",
    "        if el == 'CONJ' or el == 'CC' or el == 'CCONJ' or el == 'SCONJ':\n",
    "            new_list.append('CONJ')\n",
    "        if el == 'NUM' or el == 'NUMR' or el == 'ANUM':\n",
    "            new_list.append('NUM')\n",
    "        if el == 'PRCL' or el == 'PART':\n",
    "            new_list.append('PART')\n",
    "        #else:\n",
    "        #    new_list.append(el)\n",
    "    return(new_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сводим все к единому стандарту и проверяем качество анализаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_pym = convertizer(train_pym) #пайморфи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8173913043478261"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(fin_pym, morph_rus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_mystem = convertizer(train_mystem) #майстем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8782608695652174"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(fin_mystem, morph_rus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_natasha = convertizer(train_natasha) #наташа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8347826086956521"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(fin_natasha, morph_rus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_spacy = convertizer(train_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7927927927927928"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(fin_spacy, morph_eng_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_nltk = convertizer(train_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7117117117117117"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(fin_nltk, morph_eng_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Автоматическая разметка английского текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = clean_txt(txt_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Sentence 0 --\n",
      "\n",
      "-- Sentence 1 --\n",
      "['DET', 'NOUN', 'NOUN', 'DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'PART', 'VERB', 'ADP', 'DET', 'NOUN', 'PRON', 'VERB', 'DET', 'NOUN', 'PART', 'VERB', 'DET', 'NOUN', 'NOUN', 'PRON', 'AUX', 'NOUN', 'PART', 'VERB', 'ADP', 'DET', 'NOUN', 'CCONJ', 'PRON', 'AUX', 'DET', 'NOUN', 'DET', 'VERB', 'PART', 'AUX', 'VERB', 'SCONJ', 'DET', 'NOUN', 'AUX', 'AUX', 'VERB', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'PRON', 'VERB', 'DET', 'NOUN', 'SCONJ', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'DET', 'ADV', 'VERB', 'SCONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'DET', 'NOUN', 'SCONJ', 'SCONJ', 'PRON', 'AUX', 'NOUN', 'ADV', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'VERB', 'NOUN', 'PRON', 'AUX', 'ADJ', 'SCONJ', 'PRON', 'VERB', 'VERB']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Загружаем весь пайплайн для английского\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Обрабатываем текст\n",
    "doc = nlp(eng)\n",
    "\n",
    "train_spacy = []\n",
    "# Выведем токены, леммы и теги\n",
    "for i, s in enumerate(doc.sents):\n",
    "    print(\"\\n-- Sentence %d --\" % i)\n",
    "    for t in s:\n",
    "        train_spacy.append(t.pos_)\n",
    "print(train_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = word_tokenize(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_pos = nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nltk = []\n",
    "for el in nltk_pos:\n",
    "    train_nltk.append(el[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим все к одному формату и измеряем качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_spacy = convertizer(train_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7927927927927928"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(fin_spacy, morph_eng_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_nltk = convertizer(train_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7117117117117117"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(fin_nltk, morph_eng_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
