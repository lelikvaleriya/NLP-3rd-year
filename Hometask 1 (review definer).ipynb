{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html import unescape\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = session.get('https://www.kinopoisk.ru/reviews/type/comment/status/good/#list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Открываем страницу с 50 положительными отзывами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.kinopoisk.ru/reviews/type/comment/status/good/period/month/perpage/50/#list'\n",
    "req = session.get(url, headers={'User-Agent': ua.random})\n",
    "page = req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим тег, внутри которого лежат тексты рецензий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find_all('span', {'class': '_reachbanner_'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_str = str(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чистим текст сначала от лишних знаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_str = re.sub('\\xa0', ' ', reviews_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставляем только кириллицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = re.compile('[^а-яёА-ЯЁ ]')\n",
    "pos_reviews = reg.sub(' ', cleaned_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все то же самое делаем для негативных рецензий и тестовых"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.kinopoisk.ru/reviews/type/comment/status/bad/#list'\n",
    "req = session.get(url, headers={'User-Agent': ua.random})\n",
    "page = req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_neg = soup.find_all('span', {'class': '_reachbanner_'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_str_neg = str(reviews_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_str_neg = re.sub('\\xa0', ' ', reviews_str_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = re.compile('[^а-яёА-ЯЁ ]')\n",
    "neg_reviews = reg.sub(' ', cleaned_str_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://www.kinopoisk.ru/reviews/type/comment/period/month/perpage/25/#list'\n",
    "req = session.get(url, headers={'User-Agent': ua.random})\n",
    "page = req.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = soup.find_all('span', {'class': '_reachbanner_'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_for_test = str(reviews_test)\n",
    "r = reviews_for_test.split('<span class=\"_reachbanner_\" itemprop=\"reviewBody\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь уже нужно, чтобы каждый текст был отдельно, поэтому разделяем их и кладем 10 рецензий в список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for rew in r:\n",
    "    cleaned_str_test = re.sub('\\xa0', ' ', rew)\n",
    "    #print(cleaned_str_test)\n",
    "    reg = re.compile('[^а-яёА-ЯЁ ]')\n",
    "    test_reviews = reg.sub(' ', cleaned_str_test)\n",
    "    #print(test_reviews)\n",
    "    #while len(test) < 10:\n",
    "    test.append(test_reviews)\n",
    "test_list = []\n",
    "test_list.append(test[1:11])\n",
    "fin_list = test_list[0]\n",
    "#print(fin_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем вектор правильных ответов. 1 - положительный отзыв, 0 - отрицательный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [0, 0, 1, 0, 0, 1, 1, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датафрейм просто так, чтобы проверить, все ли в порядке "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(fin_list, label)), columns =['review', 'label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Довольно вторичный фильм с заезженными клеше  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Биографические фильмы   это здорово  Понятно  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Это какая то фантастика  Никто б...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Зарубежные ремейки успешных фильмов в США стоя...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>но  как говориться  молчать не могу      пан...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Замечательный  одновременно легкий и глубокий ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Первый раз я смотрел этот фильм в кинотеатре  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Тема детей  которые выросли без родителей  ред...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Продюсеры  Ветряной реки  совместно с созда...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Каждая новая часть   лучше предыдущей  Как так...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Довольно вторичный фильм с заезженными клеше  ...      1\n",
       "1  Биографические фильмы   это здорово  Понятно  ...      1\n",
       "2                Это какая то фантастика  Никто б...      0\n",
       "3  Зарубежные ремейки успешных фильмов в США стоя...      0\n",
       "4    но  как говориться  молчать не могу      пан...      1\n",
       "5  Замечательный  одновременно легкий и глубокий ...      0\n",
       "6  Первый раз я смотрел этот фильм в кинотеатре  ...      1\n",
       "7  Тема детей  которые выросли без родителей  ред...      0\n",
       "8     Продюсеры  Ветряной реки  совместно с созда...      1\n",
       "9  Каждая новая часть   лучше предыдущей  Как так...      0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для приведения к нижнему регистру, токенизации, лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prep(text):\n",
    "    text = text.lower()\n",
    "    tokenized = word_tokenize(text)\n",
    "    lemmas = []\n",
    "    for word in tokenized:\n",
    "        ana = morph.parse(word)\n",
    "        first = ana[0]\n",
    "        lemma = first.normal_form\n",
    "        lemmas.append(lemma)\n",
    "    return(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем разные множества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_set = set(text_prep(pos_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_set = set(text_prep(neg_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = positive_set.difference(negative_set) #уникальные элементы только в позитивных отзывах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = negative_set.difference(positive_set) #уникальные элементы только в негативных отзывах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_list = text_prep(pos_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_list = text_prep(neg_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем редкие слова и удаляем их из множеств"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = collections.Counter(positive_list)\n",
    "c_list = c.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_words_pos = []\n",
    "for el in c_list:\n",
    "    if el[1] == 1 or el[1] == 2:\n",
    "        rare_words_pos.append(el[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos = []\n",
    "for word in positive_list:\n",
    "    if word not in rare_words_pos:\n",
    "        new_pos.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_neg = collections.Counter(negative_list)\n",
    "c_list_neg = c_neg.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_words_neg = []\n",
    "for el in c_list:\n",
    "    if el[1] == 1 or el[1] == 2:\n",
    "        rare_words_neg.append(el[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_neg = []\n",
    "for word in negative_list:\n",
    "    if word not in rare_words_neg:\n",
    "        new_neg.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pos_set = set(new_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_neg_set = set(new_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем сеты из списков, из которых с помощью Counter убраны слова, встречающиеся 1-2 раза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_positive = new_pos_set.difference(new_neg_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_negative = new_neg_set.difference(new_pos_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, определяющая положительная рецензия или отрицательная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_definer(text):\n",
    "    y = []\n",
    "    positive_words = 0\n",
    "    negative_words = 0\n",
    "    for text in fin_list:\n",
    "        text = text_prep(text)\n",
    "        for word in text:\n",
    "            if word in unique_positive:\n",
    "                positive_words += 1\n",
    "            if word in unique_negative:\n",
    "                negative_words += 1\n",
    "        if positive_words >= negative_words:\n",
    "            y.append(1)\n",
    "        if negative_words > positive_words:\n",
    "            y.append(0)\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for text in fin_list:\n",
    "    y = super_definer(text)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как можно улучшить программу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Например, исключить слова, которые в принципе являются частотными в языке. Это значит, они встречаются не только в положительных или отрицательных отзывах, но и в обычных не эмоционально окрашенных текстах.\n",
    "2. Добавить в положительное или отрицательное множество словосочетания, помимо отдельных слов.\n",
    "3. Возможно, применить метод TF-IDF, который поможет выделить значимые слова конкретно для положительных или отрицательных отзывов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
